any(grepl("rjson",installed.packages()))
json_text <- paste(readLines("input.json"), collapse = "")
# Parse the JSON
data <- fromJSON(json_text)
# Print the result
print(data)
library(dplyr)
data(iris)
head(iris)
tail(iris)
iris_grouped <- group_by(iris,Species)
head(iris_grouped)
summary(iris)
summarize(
iris_grouped,
mean_sepal_length = mean(Sepal.Length),
sd_sepal_length = sd(Sepal.Length)
)
summarize(iris_grouped, count = n())
summarize(
iris_grouped,
percent = sum(Sepal.Length > 5.5)/n()
)
data <- read.csv("sample.csv")
print(data)
data <- read.csv("sample.csv")
print(data)
# number of columns and rows.
data <- read.csv("input.csv")
print(is.data.frame(data))
print(ncol(data))
print(nrow(data))
library("xlsx")
# Read the first worksheet in the file input.xlsx.
data <- read.xlsx("input.xlsx", sheetIndex = 1)
print(data)
library("XML")
# Also load the other required package.
library("methods")
# Give the input file name to the function.
result <- xmlParse(file = "input.xml")
# Print the result.
print(result)
library(rjson)
# Read the file as text
json_text <- paste(readLines("input.json"), collapse = "")
# Parse the JSON
data <- fromJSON(json_text)
# Print the result
print(data)
install.packages("dplyr")
library(dplyr)
data(iris)
head(iris)
tail(iris)
iris_grouped <- group_by(iris,Species)
head(iris_grouped)
summary(iris)
summarize(
iris_grouped,
mean_sepal_length = mean(Sepal.Length),
sd_sepal_length = sd(Sepal.Length)
)
summarize(iris_grouped, count = n())
summarize(
iris_grouped,
percent = sum(Sepal.Length > 5.5)/n()
)
input <- mtcars[,c('mpg','cyl')]
input
summary(input)
head(input)
tail(input)
data("mtcars")
head(mtcars)
summary(mtcars)
data(iris)
head(iris)
str(iris)
# Box plot for Sepal.Length
boxplot(iris$Sepal.Length,
main="Box Plot of Sepal.Length",
col="lightblue",
horizontal=TRUE)
data(iris)
head(iris)
str(iris)
# Box plot for Sepal.Length
boxplot(iris$Sepal.Length,
main="Box Plot of Sepal.Length",
col="lightblue",
horizontal=TRUE)
# Box plot for all numeric variables
boxplot(iris[,1:4], main="Box Plot for All Numeric Features", col=rainbow(4))
plot(iris$Sepal.Length, iris$Sepal.Width,
main="Scatter Plot: Sepal Length vs Sepal Width",
xlab="Sepal Length",
ylab="Sepal Width",
pch=19,
col=iris$Species)
legend("topright", legend=levels(iris$Species), col=1:3, pch=19)
# Boxplot for Petal.Length with outliers
boxplot(iris$Petal.Length,
main="Petal Length Box Plot with Outliers",
col="orange",
horizontal=TRUE)
# Identify outliers programmatically
outliers <- boxplot.stats(iris$Petal.Length)$out
print(outliers)
plot(iris$Sepal.Length, iris$Sepal.Width,
main="Scatter Plot: Sepal Length vs Sepal Width",
xlab="Sepal Length",
ylab="Sepal Width",
pch=19,
col=iris$Species)
legend("topright", legend=levels(iris$Species), col=1:3, pch=19)
plot(iris$Sepal.Length, iris$Sepal.Width,
main="Scatter Plot: Sepal Length vs Sepal Width",
xlab="Sepal Length",
ylab="Sepal Width",
pch=19,
col=iris$Species)
legend("topright", legend=levels(iris$Species), col=1:3, pch=19)
# Boxplot for Petal.Length with outliers
boxplot(iris$Petal.Length,
main="Petal Length Box Plot with Outliers",
col="orange",
horizontal=TRUE)
# Identify outliers programmatically
outliers <- boxplot.stats(iris$Petal.Length)$out
print(outliers)
hist(iris$Sepal.Length,
main="Histogram of Sepal Length",
xlab="Sepal Length",
col="skyblue",
border="black")
species_count <- table(iris$Species)
barplot(species_count,
main="Number of Iris per Species",
col=rainbow(length(species_count)),
border="black")
species_count <- table(iris$Species)
barplot(species_count,
main="Number of Iris per Species",
col=rainbow(length(species_count)),
border="black")
pie(species_count,
main="Pie Chart of Iris Species",
col=rainbow(length(species_count)))
# 3D Pie Chart
pie3D(species_count,
main="3D Pie Chart of Iris Species",
explode=0.1,
col=rainbow(length(species_count)),
labelcex=1)
install.packages("plotly")
library(plotly)
install.packages("plotrix")
library(plotrix)
library(plotrix)
# 3D Pie Chart
pie3D(species_count,
main="3D Pie Chart of Iris Species",
explode=0.1,
col=rainbow(length(species_count)),
labelcex=1)
library(plotly)
# Numeric columns from iris
x <- iris$Sepal.Length
y <- iris$Sepal.Width
fig <- plot_ly(
x = ~x,
y = ~y,
type = "histogram2d",
colorscale = "Viridis"   # colorful
)
fig <- fig %>% layout(
title = "3D Histogram of Sepal Length vs Sepal Width",
xaxis = list(title = "Sepal Length"),
yaxis = list(title = "Sepal Width")
)
fig  # Display interactive 3D histogram
# Load the built-in mtcars dataset
data(mtcars)
# Display the first few rows
head(mtcars)
# Summary statistics
summary(mtcars)
# Check the structure
str(mtcars)
# Plot mpg (dependent variable) vs wt (independent variable)
plot(mtcars$wt, mtcars$mpg, main = "MPG vs Weight",
xlab = "Weight (1000 lbs)", ylab = "Miles per Gallon",
pch = 19, col = "blue")
# Fit a linear regression model
model1 <- lm(mpg ~ wt, data = mtcars)
# View the summary of the model
summary(model1)
# Diagnostic plots
par(mfrow = c(2, 2))
plot(model2)
model2 <- lm(mpg ~ wt + hp, data = mtcars)
# Model summary
summary(model2)
# Diagnostic plots
par(mfrow = c(2, 2))
plot(model2)
new_data <- data.frame(wt = c(3, 2.5), hp = c(110, 90))
predicted_mpg <- predict(model2, newdata = new_data)
predicted_mpg
# Load the built-in mtcars dataset
data(mtcars)
# Display the first few rows
head(mtcars)
# Summary statistics
summary(mtcars)
str(mtcars)
plot(mtcars$wt, mtcars$mpg, main = "MPG vs Weight",
xlab = "Weight (1000 lbs)", ylab = "Miles per Gallon",
pch = 19, col = "blue")
model1 <- lm(mpg ~ wt, data = mtcars)
# View the summary of the model
summary(model1)
model1 <- lm(mpg ~ wt, data = mtcars)
# View the summary of the model
summary(model1)
# Plot mpg (dependent variable) vs wt (independent variable)
plot(mtcars$wt, mtcars$mpg, main = "MPG vs Weight",
xlab = "Weight (1000 lbs)", ylab = "Miles per Gallon",
pch = 19, col = "blue")
# Fit a linear regression model
model1 <- lm(mpg ~ wt, data = mtcars)
# View the summary of the model
summary(model1)
model2 <- lm(mpg ~ wt + hp, data = mtcars)
# Model summary
summary(model2)
# Diagnostic plots
par(mfrow = c(2, 2))
plot(model2)
# Diagnostic plots
par(mfrow = c(2, 2))
plot(model2)
# Example prediction
new_data <- data.frame(wt = c(3, 2.5), hp = c(110, 90))
predicted_mpg <- predict(model2, newdata = new_data)
predicted_mpg
# Load the dataset
data(mtcars)
head(mtcars)
# Load the dataset
data(mtcars)
head(mtcars)
# Compute correlation matrix for all numeric variables
cor_matrix <- cor(mtcars)
# Display the correlation matrix
print(cor_matrix)
if(!require(corrplot)) install.packages("corrplot")
library(corrplot)
library(corrplot)
# Plot correlation matrix
corrplot(cor_matrix, method = "color", type = "upper",
tl.col = "black", tl.srt = 45,
addCoef.col = "black", number.cex = 0.7,
col = colorRampPalette(c("blue", "white", "red"))(200),
title = "Correlation Plot for mtcars", mar = c(0,0,2,0))
mtcars$cyl <- as.factor(mtcars$cyl)
# Fit a linear model with mpg depending on weight and cylinder category
ancova_model <- lm(mpg ~ wt + cyl, data = mtcars)
# Summary of model
summary(ancova_model)
anova(ancova_model)
library(ggplot2)
library(ggplot2)
ggplot(mtcars, aes(x = wt, y = mpg, color = cyl)) +
geom_point(size = 3) +
geom_smooth(method = "lm", se = FALSE) +
labs(title = "ANCOVA: MPG vs Weight by Cylinder Category",
x = "Weight (1000 lbs)", y = "Miles per Gallon (mpg)") +
theme_minimal()
# Load built-in dataset
data(volcano)
# Create x and y coordinates
x <- 10 * (1:nrow(volcano))
y <- 10 * (1:ncol(volcano))
# Compute colors for shading
z <- volcano
zlim <- range(z)
color <- terrain.colors(100)
zfacet <- (z[-1, -1] + z[-1, -ncol(z)] + z[-nrow(z), -1] + z[-nrow(z), -ncol(z)]) / 4
facetcol <- color[cut(zfacet, 100)]
# Create a 3D surface plot
persp(x, y, z,
col = facetcol,          # add color
theta = 45, phi = 25,    # viewing angles (change for different perspectives)
expand = 0.5,            # scaling in z-direction
shade = 0.5,             # add shading effect
ltheta = 120,            # light direction
ticktype = "detailed",   # detailed axis ticks
xlab = "X coordinate",
ylab = "Y coordinate",
zlab = "Height",
main = "3D Surface Plot of Volcano Dataset")
data <- data.frame(
Gender = c("Male", "Female", "Female", "Male", "Male", "Female"),
Preference = c("Yes", "No", "Yes", "No", "Yes", "Yes")
)
# View data
print(data)
data <- data.frame(
Gender = c("Male", "Female", "Female", "Male", "Male", "Female"),
Preference = c("Yes", "No", "Yes", "No", "Yes", "Yes")
)
# View data
print(data)
table_data <- table(data$Gender, data$Preference)
# View table
print(table_data)
# Perform Chi-Square test
chi_result <- chisq.test(table_data)
# View results
print(chi_result)
library(MASS)        # for Boston dataset
library(dplyr)       # data manipulation
library(ggplot2)     # visualization
library(infotheo)    # for information gain
install.packages("infotheo")
library(MASS)        # for Boston dataset
library(dplyr)       # data manipulation
library(ggplot2)     # visualization
library(infotheo)    # for information gain
data("Boston")
df <- Boston
head(df)
# Check structure
str(df)
# Summary statistics
summary(df)
# Check for missing values
colSums(is.na(df))
# Example of replacing missing numeric values with mean
df_clean <- df %>%
mutate_all(~ifelse(is.na(.), mean(., na.rm = TRUE), .))
# Remove duplicates
df_clean <- df_clean %>% distinct()
# Detect and cap outliers
for(col in names(df_clean)){
if(is.numeric(df_clean[[col]])){
Q1 <- quantile(df_clean[[col]], 0.25)
Q3 <- quantile(df_clean[[col]], 0.75)
IQR <- Q3 - Q1
lower <- Q1 - 1.5 * IQR
upper <- Q3 + 1.5 * IQR
df_clean[[col]][df_clean[[col]] < lower] <- lower
df_clean[[col]][df_clean[[col]] > upper] <- upper
}
}
df_clean <- df_clean %>%
mutate_if(is.character, as.factor)
# Discretize numeric data (information gain needs discrete values)
df_discrete <- discretize(df_clean)
# Compute information gain with respect to 'medv'
ig <- information.gain(medv ~ ., df_discrete)
df_discrete <- discretize(df_clean)
data(volcano)
# Create x and y coordinates
x <- 10 * (1:nrow(volcano))
y <- 10 * (1:ncol(volcano))
# Compute colors for shading
z <- volcano
zlim <- range(z)
color <- terrain.colors(100)
zfacet <- (z[-1, -1] + z[-1, -ncol(z)] + z[-nrow(z), -1] + z[-nrow(z), -ncol(z)]) / 4
facetcol <- color[cut(zfacet, 100)]
# Create a 3D surface plot
persp(x, y, z,
col = facetcol,          # add color
theta = 45, phi = 25,    # viewing angles (change for different perspectives)
expand = 0.5,            # scaling in z-direction
shade = 0.5,             # add shading effect
ltheta = 120,            # light direction
ticktype = "detailed",   # detailed axis ticks
xlab = "X coordinate",
ylab = "Y coordinate",
zlab = "Height",
main = "3D Surface Plot of Volcano Dataset")
# Install & load necessary packages
install.packages(c("dplyr", "ggplot2", "FSelector", "data.table"))
library(dplyr)
library(ggplot2)
library(FSelector)
install.packages(c("dplyr", "ggplot2", "FSelector", "data.table"))
install.packages(c("dplyr", "ggplot2", "FSelector", "data.table"))
library(dplyr)
library(ggplot2)
library(FSelector)
library(data.table)
# 1. Load dataset
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data"
col_names <- c("symboling", "normalized_losses", "make", "fuel_type", "aspiration",
"num_doors", "body_style", "drive_wheels", "engine_location", "wheel_base",
"length", "width", "height", "curb_weight", "engine_type", "num_cylinders",
"engine_size", "fuel_system", "bore", "stroke", "compression_ratio",
"horsepower", "peak_rpm", "city_mpg", "highway_mpg", "price")
auto <- fread(url, na.strings = "?", col.names = col_names)
# 2. Quick look at data
str(auto)
summary(auto)
# 3. Handle missing values (simplest way: remove rows with NA)
auto <- na.omit(auto)
# 4. Convert numeric columns
auto$price <- as.numeric(auto$price)
auto$horsepower <- as.numeric(auto$horsepower)
auto$engine_size <- as.numeric(auto$engine_size)
# 5. Feature selection using Information Gain
# Discretize price into 3 classes (Low, Medium, High)
auto$price_class <- cut(auto$price, breaks=3, labels=c("Low","Medium","High"))
# Calculate information gain
info_gain <- information.gain(price_class ~ ., data = auto)
# Sort features by importance
info_gain <- info_gain[order(-info_gain$attr_importance), , drop = FALSE]
print(info_gain)
# 6. Visualize Information Gain
info_df <- data.frame(Feature = rownames(info_gain), InfoGain = info_gain$attr_importance)
ggplot(info_df, aes(x = reorder(Feature, InfoGain), y = InfoGain)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = "Information Gain of Features", x = "Feature", y = "Info Gain") +
theme_minimal()
# Create data frame
data <- data.frame(
Gender = c("Male", "Female", "Female", "Male", "Male", "Female"),
Preference = c("Yes", "No", "Yes", "No", "Yes", "Yes")
)
# View data
print(data)
# Create contingency table
table_data <- table(data$Gender, data$Preference)
# View table
print(table_data)
# Perform Chi-Square test
chi_result <- chisq.test(table_data)
# View results
print(chi_result)
# Create data frame
data <- data.frame(
Gender = c("Male", "Female", "Female", "Male", "Male", "Female"),
Preference = c("Yes", "No", "Yes", "No", "Yes", "Yes")
)
# View data
print(data)
# Create contingency table
table_data <- table(data$Gender, data$Preference)
# View table
print(table_data)
# Perform Chi-Square test
chi_result <- chisq.test(table_data)
# View results
print(chi_result)
library(dplyr)
library(ggplot2)
library(FSelector)
library(data.table)
# 1. Load dataset
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data"
col_names <- c("symboling", "normalized_losses", "make", "fuel_type", "aspiration",
"num_doors", "body_style", "drive_wheels", "engine_location", "wheel_base",
"length", "width", "height", "curb_weight", "engine_type", "num_cylinders",
"engine_size", "fuel_system", "bore", "stroke", "compression_ratio",
"horsepower", "peak_rpm", "city_mpg", "highway_mpg", "price")
auto <- fread(url, na.strings = "?", col.names = col_names)
# 2. Quick look at data
str(auto)
summary(auto)
# 3. Handle missing values (simplest way: remove rows with NA)
auto <- na.omit(auto)
# 4. Convert numeric columns
auto$price <- as.numeric(auto$price)
auto$horsepower <- as.numeric(auto$horsepower)
auto$engine_size <- as.numeric(auto$engine_size)
# 5. Feature selection using Information Gain
# Discretize price into 3 classes (Low, Medium, High)
auto$price_class <- cut(auto$price, breaks=3, labels=c("Low","Medium","High"))
# Calculate information gain
info_gain <- information.gain(price_class ~ ., data = auto)
# Sort features by importance
info_gain <- info_gain[order(-info_gain$attr_importance), , drop = FALSE]
print(info_gain)
# 6. Visualize Information Gain
info_df <- data.frame(Feature = rownames(info_gain), InfoGain = info_gain$attr_importance)
ggplot(info_df, aes(x = reorder(Feature, InfoGain), y = InfoGain)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(title = "Information Gain of Features", x = "Feature", y = "Info Gain") +
theme_minimal()
#1. Create a list containing strings, a vector, a logical value, and numbers.
list_data = list("Dhruv","Pizza", c(2,4,8), TRUE, 121.17, 74.33)
print("Data of the list:")
print(list_data)
#1. Create a list containing strings, a vector, a logical value, and numbers.
list_data = list("Dhruv","Pizza", c(2,4,8), TRUE, 121.17, 74.33)
print("Data of the list:")
print(list_data)
#Q2. Write an R program to create a Data frame which contains details of 5 employees and display the details.
Employees = data.frame(
Name=c("Dhruv","Manya","Lakshya","Ankita","Shivam"),
Gender = c("M","F","M","F","M"),
Age = c(20,20,19,19,18),
SSN = c("1234-34-2345","123-44-779","556-24-443","128-56-987","445-67-874")
)
print("Details of the employees:")
print(Employees)
